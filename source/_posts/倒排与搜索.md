---
title: 倒排与搜索
date: 2020-12-31 10:56:29
tags: ES
cover: https://img9.51tietu.net/pic/2019-091317/c1p02kfk1lwc1p02kfk1lw.jpg
---

## 为什么百度这么快呢

其实我们都能说是用了倒排，包括一些搜索框架，例如 Lucene、Elasticsearch，追根到底都是倒排，那么什么是倒排呢，我们真的理解了吗？

在我理解中，倒排可以看做是成语词典，先找单个字，再到具体的地方去找到对应的词组

来看一个经典的东西

![](1.png)

按照每个词语出现在文档中的位置和字数，可以生成下面的数据

![](2.jpg)

例如

> (1;1;<1>) 

表示这个词出现在了 文章1 里面，出现了1次，出现的位置是1

这样子，搜素引擎就可以根据你的关键词在倒排列表中找到含有这个关键词的文档集合，然后根据关键词在文档集合中各个文档出现的频率和位置综合判断返回给你排序后的文档

实际上很多搜索引擎基本就是这样做的，只不过各家还有别的参考标准，比如百度还会参考热度，你的搜索记录，还有网站给的钱（你懂的）等等综合打分，按评分高低返回搜索结果的排序

假设世界上只有5个文档，那么上面的东西完全够了，但实际上，世界上有亿万个文档，此时，问题的性质已经变了，不是找不找得到的问题，而是怎么找更快，更准的问题，这需要算法

### 第一个问题：怎么关联

比如你输入苹果的时候，我记录的文档里面也有苹果，百度如何将你的关键词和他内部倒排列表的“苹果”一词联系起来？

计算机是不认识“苹果”的，这里，可以通过哈希的方法将“苹果”转换为一个编号

比如 苹果是 2 个字，我们可以hash到2，梨 是 1 个字，我们可以hash到1，从而 hash 冲突就出现了，因为 桃子 也是 2，这里与 java 中的 HashMap 处理方式可以一样，数组加链表，链表长了过后转换成 红黑树之类的

### 第二个问题：文档过多

由于文档的数量庞大，我们获取的文档往往编号位数都很多，而不像上图那样1,2,3,4,5,导致倒排列表无谓的扩大，所以我们这里进行作差

```
单词 -> 187 -> 196 -> 199
单词 -> 187 -> 9   -> 3
```

就是后面的文档编号减去前面的，在取文档（从磁盘中读取）的时候加回来即可

### 第三个问题：读取文档

* 两次遍历法

第一遍：扫描文档集合，找到文档数量N,文档集合内所包含的不同单词数M,和每个单词出现的频率DF，以及一些别的必要信息，这些东西所占内存加起来，得到需要开辟的内存空间，
第二遍扫描，就是边扫描，匹配对应的文档编号（三元组中的第一个数），载入内存

但是这个方法有一个问题，那就是文档集合有多大，内存就有多大，所以，很可能内存会溢出，不过都放在内存中速度也很快，这是一种空间换时间的方法

* 排序法

我们需要解析文档，构造（单词ID,文档ID，单词频率）三元组，然后进行排序，按单词ID,文档ID,单词频率先后排，最后如果规定的内存满了，就将这些三元组通通写入一个临时文件A中

![](https://pic2.zhimg.com/80/v2-f76b63f25cd6ca5ddde268c71e259d11_720w.jpg)

可能解析50个文档后规定的内存就满了，然后把这些三元组们写入磁盘临时文件A，就可以再读下一篇50个文档了，注意，词典是不断增加的，比如前50个文档只有上面7个单词，后50个文档可能出现了别的单词，此时要插入词典中，词典一直在内存

这样，只用固定大小的内存就可以50一批的解析完所有文档，写入了一个个的临时文件A,B,C,D，再将这些临时文件合并，就是把他们分别读入内存中的缓冲区，合成最终索引后再写入磁盘，这样通过最终索引就知道有哪些单词对应多少文档，还有频率，然后根据这些开辟内存空间读取进入内存返回给你即可

![](https://pic3.zhimg.com/80/v2-f598badc8baf61792234a7957b9b83c6_720w.jpg)

## 总结
这只是一个开篇最最简单的介绍，倒排索引只是其中之一，其它的关键词有：udw，机房，架构，c语言，多路召回，mola，缓存，gpu加速等等，累计上千人的前后二十年。